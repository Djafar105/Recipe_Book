
### **Core Skills to Master** *(ordered)*

*  Probability theory (discrete & continuous)
    
- Random variables, distributions, expectations
    
- Hypothesis testing, p-values, confidence intervals
    
- Bayesian inference (priors, posteriors, conjugacy)
    
- Estimation theory (MLE, MAP)
    
- Regression (linear, logistic), model assumptions
    
- Resampling methods (bootstrapping, cross-validation)
### **Recommended Path**

1. **Harvard STAT 110 – Probability** (Joe Blitzstein)  
    – Full 10-week video series + _Intro to Probability_ textbook [classcentral.com+9reddit.com+9simonsfoundation.org+9](https://www.reddit.com/r/learnmachinelearning/comments/jsse9a/recommendations_for_probability_and_statistics/?utm_source=chatgpt.com)[arxiv.org](https://arxiv.org/abs/1304.2333?utm_source=chatgpt.com)[coursera.org](https://www.coursera.org/courses?query=computational+neuroscience&utm_source=chatgpt.com)
    
2. **Khan Academy – Statistics & Probability** (complimentary review) [careerkarma.com](https://careerkarma.com/blog/computational-neuroscience/?utm_source=chatgpt.com)
    
3. **Casella & Berger – Statistical Inference** (optional deeper theory) [en.wikipedia.org+2reddit.com+2coursera.org+2](https://www.reddit.com/r/learnmachinelearning/comments/jsse9a/recommendations_for_probability_and_statistics/?utm_source=chatgpt.com)  
    – Covers inference/bayes at rigorous level
    
4. **Modern Bayesian Methods**  
    – _Analysis of Neural Data_ (Kass et al) – applied Bayesian spikes/statistics [en.wikipedia.org+1en.wikipedia.org+1](https://en.wikipedia.org/wiki/Robert_Kass?utm_source=chatgpt.com)  
    – _A primer on information theory_ – introduces entropy, mutual info [simonsfoundation.org+15arxiv.org+15arxiv.org+15](https://arxiv.org/abs/1304.2333?utm_source=chatgpt.com)
    
5. **Practical Application**  
    – Implement linear/logistic regression (+ confidence intervals) in Python/R  
    – Simulate Bayesian updating (e.g., coin flips, spike trains)  
    – Practice hypothesis testing: t-test, ANOVA, permutation tests
## Math
### **Core Skills You Must Master**

- Linear algebra (vectors, matrices, eigen)
    
- Calculus & ODEs (derivatives, integrals, dynamics)
    
- Probability theory overlap
    
- Intro to dynamical systems (phase planes, fixed points)
    
- Signal transforms (Fourier basics)
    
- Optional: information geometry, RKHS basics
    

### **Recommended Path**

1. **Linear Algebra**  
    – MIT OCW (Gilbert Strang) or _Linear Algebra Done Right_  
    – Practice solving systems, eigen-analysis, SVD
    
2. **Differential Equations & Dynamical Systems**  
    – MIT OCW 18.03 DE course  
    – For neural ODEs: _Neuronal Dynamics_ (Gerstner & Kistler)
    
3. **Mathematical Tools for Neuroscience (Princeton NEU 314)** – free syllabus + code [reddit.com+1classcentral.com+1](https://www.reddit.com/r/learnmachinelearning/comments/jsse9a/recommendations_for_probability_and_statistics/?utm_source=chatgpt.com)[snastase.github.io+1coursera.org+1](https://snastase.github.io/teaching/neu314?utm_source=chatgpt.com)[reddit.com+2linkedin.com+2glassdoor.com+2](https://www.linkedin.com/in/andrew-cawley-bennett-phd-2981421b5?utm_source=chatgpt.com)[en.wikipedia.org+2simonsfoundation.org+2careerkarma.com+2](https://www.simonsfoundation.org/collaborations/global-brain/online-resources-for-systems-and-computational-neuroscience/?utm_source=chatgpt.com)  
    – Bridges linear algebra, stats, ML with Python notebooks
    
4. **Information Theory Primer** as above – extends calculus/prob concepts to neural coding
    
5. **Probabilistic Numerics (Optional)** – how to embed uncertainty in ODE solving [snastase.github.io](https://snastase.github.io/teaching/neu314?utm_source=chatgpt.com)[en.wikipedia.org+1en.wikipedia.org+1](https://en.wikipedia.org/wiki/Joshua_Vogelstein?utm_source=chatgpt.com)[en.wikipedia.org](https://en.wikipedia.org/wiki/Probabilistic_numerics?utm_source=chatgpt.com)
    
6. **Hands-on**:  
    – Derive and simulate LIF neuron (1 → many models)  
    – Analyze stability of a 2-D ODE  
    – Compute Fourier transform of synthetic neural signal